# Email Classifier â€” MVP (FastAPI + DDD-lite)

MVP enxuto que recebe **texto direto** ou **arquivos (.pdf / .txt)**, normaliza para JSON, roda **NLP bÃ¡sico** (prÃ©-process + tokenizaÃ§Ã£o), classifica o e-mail como **Produtivo** ou **Improdutivo** e gera uma **resposta sugerida**.  
Arquitetura **hexagonal** (ports & adapters), com **use case** Ãºnico e adapters substituÃ­veis (rule-based por padrÃ£o e LLM opcional).

---

## âœ¨ Features
- `POST /classify` aceita **JSON** ou **multipart** com arquivo `.pdf`/`.txt`  
- **Facade de arquivos** (PDF/TXT â†’ texto)  
- **NLP** simples: lowercasing, remoÃ§Ã£o de stopwords, tokenizaÃ§Ã£o por regex  
- **Classificador**:
  - ğŸ¯ **Rule-based** (padrÃ£o, sem custo)
  - ğŸ¤– **OpenAI LLM** (opcional via `OPENAI_API_KEY`)
- **Resposta sugerida** automÃ¡tica e curta
- `GET /health` para monitoramento
- Swagger em `/docs`
- `GET /logs` para consultar histÃ³rico de classificaÃ§Ãµes (armazenadas em SQLite)

---

## ğŸ—ï¸ Arquitetura (VisÃ£o LÃ³gica)

**Fluxo**  
1) **Entrada** â†’ JSON direto *ou* upload `.pdf/.txt`  
2) **Facade Files** â†’ extrai texto e normaliza  
3) **NLP** â†’ `preprocess â†’ tokenize`  
4) **Classifier** â†’ rule-based (default) *ou* LLM  
5) **Responder** â†’ mensagem curta coerente  
6) **PersistÃªncia** â†’ registro no banco SQLite  
7) **SaÃ­da** â†’ `category | reason | suggested_reply | tokens | custo`

**DDD + Hexagonal**  
- **Domain**: entidades (`Email`, `ClassificationResult`, `ClassificationLog`), portas (`TokenizerPort`, `ClassifierPort`, `ReplySuggesterPort`, `ProfilePort`, `LogRepositoryPort`), erros  
- **Application**: `ClassifyEmailUseCase` + `FileFacade`  
- **Infrastructure (adapters)**: extractors PDF/TXT, tokenizer simples, classifiers (rule-based, OpenAI), responder, repositÃ³rios SQL  
- **Interfaces**: HTTP (FastAPI routers)

---

## ğŸ“ Estrutura de Pastas

```
email_classifier/
â”œâ”€ app/
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ bootstrap.py
â”‚  â”œâ”€ interfaces/http/routers.py
â”‚  â”œâ”€ application/
â”‚  â”‚   â”œâ”€ dto.py
â”‚  â”‚   â””â”€ use_cases/classify_email.py
â”‚  â”œâ”€ domain/
â”‚  â”‚   â”œâ”€ entities.py
â”‚  â”‚   â”œâ”€ ports.py
â”‚  â”‚   â”œâ”€ errors.py
â”‚  â”‚   â””â”€ value_objects.py
â”‚  â””â”€ infrastructure/
â”‚      â”œâ”€ extractors/
â”‚      â”œâ”€ nlp/tokenizer_simple.py
â”‚      â”œâ”€ classifiers/
â”‚      â”œâ”€ responders/simple_templates.py
â”‚      â”œâ”€ repositories/sql_log_repository.py
â”‚      â””â”€ models.py
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â””â”€ .env.example
```

---

## ğŸ“¦ DependÃªncias e MotivaÃ§Ãµes

- **fastapi / uvicorn** â†’ servidor web moderno e performÃ¡tico  
- **pydantic** â†’ validaÃ§Ã£o de entrada/saÃ­da  
- **python-multipart** â†’ suporte a upload de arquivos  
- **pypdf** â†’ leitura de PDFs textuais  
- **slowapi + limits** â†’ rate limiting para proteÃ§Ã£o da API  
- **sqlalchemy + sqlmodel** â†’ persistÃªncia simples em SQLite, modelo ORM enxuto  
- **sqlite** (via SQLModel) â†’ banco leve, embarcado, ideal para logs temporÃ¡rios de classificaÃ§Ã£o  
  - usado para **armazenar histÃ³rico de requisiÃ§Ãµes** e testar diferentes modelos de IA com as mesmas entradas, ajudando a **afiar a IA** sem perder rastreabilidade  

---

## â–¶ï¸ Como Rodar (Local)

```bash
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Acesse:
- API: `http://127.0.0.1:8000`
- Docs: `http://127.0.0.1:8000/docs`

---

## ğŸ”Œ Endpoints

### `GET /health`
```json
{"status": "ok"}
```

### `POST /classify`
Aceita JSON ou arquivo (`.pdf` / `.txt`), normaliza, classifica e retorna resultado.

### `GET /logs`
Retorna histÃ³rico de classificaÃ§Ãµes persistidas em SQLite.  
Exemplo:
```json
[
  {
    "id": 1,
    "created_at": "2025-09-14T15:17:01.032369",
    "subject": "Proposta e orÃ§amento",
    "profile_id": "default",
    "category": "productive",
    "reason": "mensagem relacionada a proposta, orÃ§amento e cronograma",
    "suggested_reply": "OlÃ¡! Obrigado pelo contato..."
  }
]
```

---

## ğŸ“ PrÃ³ximos passos

- MÃ©tricas de latÃªncia/custo direto no log  
- Testar diferentes LLMs em batch com o mesmo dataset (aproveitando o SQLite)  
- Criar painel para explorar os logs  
- Expandir NLP (stemming/lemmatizaÃ§Ã£o, multilÃ­ngue)  

---

## ğŸ“œ LicenÃ§a
Uso livre neste desafio tÃ©cnico. Se for publicar, considere **MIT**.
